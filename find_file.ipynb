{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d0c7764-790b-465a-b47b-133226aa3bda",
   "metadata": {},
   "source": [
    "# Trouver le fichier à modifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73ad936f-1862-4e0c-85e1-775ecc8deae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import os\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13aa5353-583d-4bb7-9cca-5b202fcc9a9d",
   "metadata": {},
   "source": [
    "##### Creation des modèle\n",
    "\n",
    "- [CodeT5+](https://github.com/salesforce/CodeT5) sert à traduire une fonction en une phrase qui la résume ( la fonction ne doit pas faire plus de 512 tokens)\n",
    "- Bert ([MiniLM](https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2)) sert à mettre dans un embedding le texte à comparer et le code résumé\n",
    "\n",
    "Modifier la variable `device` par 'cuda' pour utiliser le GPU ce qui augmenterai les performance du modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6cefcac-abb9-4809-8515-602788ea6efd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a6b42f2d5aa42ddbfa0affab2ee426c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/1.34k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be735edbd212462888d05fc1e27a101b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/511k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c984aaae3b32450f864098695b9fe741",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/294k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40ac1ed8214c4ba29bb4c35f75f4fd0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.37M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c35a60140d744688570a5750adc6c04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)in/added_tokens.json:   0%|          | 0.00/59.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79dbe1f10e65407cb9cfad4b1085f2e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/1.03k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22aac93bd0be4bb19f36e861045cc55c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/1.07k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39a2ba2079ec4ac18ec8cec6c45a69f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)n_codet5p_bimodal.py:   0%|          | 0.00/2.81k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/Salesforce/codet5p-220m-bimodal:\n",
      "- configuration_codet5p_bimodal.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a231e5ba7674d229eb9e0356d9cc723",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)g_codet5p_bimodal.py:   0%|          | 0.00/939 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/Salesforce/codet5p-220m-bimodal:\n",
      "- modeling_codet5p_bimodal.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbb24bb0b56b4f7f82c2ee52c495e323",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/892M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddec6c292f62409594a79d6e691eafa4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)e9125/.gitattributes:   0%|          | 0.00/1.18k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7437346611e84abcb3d965b957a1f144",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d3760ba155d4a51855c46c99b9395c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)7e55de9125/README.md:   0%|          | 0.00/10.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52dc7e4f79cb4daf88eacd3b815b3ae2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)55de9125/config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e8dbfcea01e44c7942020efb94ddc57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)ce_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a66264d7c1144a7b318759fe77d274b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)125/data_config.json:   0%|          | 0.00/39.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1a0e1ef489540188b25e98467b6c97e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0302b81cc67f4527bcfcbb81864b33b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)nce_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01ff461fe41f482c9db79dcdb8262fe9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ff65a9499c0449d8fe4cce9190bdd85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)e9125/tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88b653c95ca845e093c20d2c95e20797",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e9b9e6cdbc44866b29c081442376e57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)9125/train_script.py:   0%|          | 0.00/13.2k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3704d369c1b7403888b96dcc94cee69f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)7e55de9125/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3cf7377b2194d5a80a8d00d87b04959",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)5de9125/modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "checkpoint = \"Salesforce/codet5p-220m-bimodal\"\n",
    "device = \"cpu\"  \n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint, trust_remote_code=True)\n",
    "codeT5 = AutoModel.from_pretrained(checkpoint, trust_remote_code=True).to(device)\n",
    "\n",
    "bert = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2ad462-ea06-47ec-aba9-f0f98d19b910",
   "metadata": {},
   "source": [
    "## Récupération des fonctions\n",
    "\n",
    "Ces deux blocs de codes ci-dessous servent à isoler et récupérer les fonctions qui se trouvent dans un fichier de code.\\\n",
    "Pour ce faire, nous utilisons des AST, mais cette fonction ne fonctionne sur des fichiers Python. \\\n",
    "Donc si on veut s'ouvrir à d'autres langages il faut trouver soit une fonction AST plus complète ou une autre possibilité serai d'utiliser des Regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7995fa0d-0104-40df-8fd9-d5b9571b8765",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_function_source(node):\n",
    "    if isinstance(node, ast.FunctionDef):\n",
    "        return ast.unparse(node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca04e58a-0887-41bc-a541-05fd754f2400",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:00<00:00, 360.25it/s]\n"
     ]
    }
   ],
   "source": [
    "functions_sources = []\n",
    "for filename in tqdm(os.listdir('samples/')):\n",
    "    if os.path.isfile(os.path.join('samples/', filename)):\n",
    "        with open('samples/' + filename, \"r\") as file:\n",
    "            file_content = file.read()\n",
    "        \n",
    "        parsed_tree = ast.parse(file_content)\n",
    "        \n",
    "\n",
    "        functions = [extract_function_source(node) for node in ast.walk(parsed_tree) if isinstance(node, ast.FunctionDef)]\n",
    "        if functions :\n",
    "            for function in functions:\n",
    "                functions_sources.append([\n",
    "                    'samples/' + filename,\n",
    "                    function,\n",
    "                ])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495356df-e613-45f8-9788-4010e0649e0e",
   "metadata": {},
   "source": [
    "## Résumé\n",
    "\n",
    "Cette partie permet de transformer le code en texte (anglais)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e16f9d4-81ee-49d5-81db-a029ce7f39ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 83/136 [00:48<00:29,  1.78it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (608 > 512). Running this sequence through the model will result in indexing errors\n",
      "100%|██████████| 136/136 [01:19<00:00,  1.72it/s]\n"
     ]
    }
   ],
   "source": [
    "for function_source in tqdm(functions_sources):\n",
    "    input_ids = tokenizer(function_source[1], return_tensors=\"pt\").input_ids.to(device)\n",
    "\n",
    "\n",
    "    generated_ids = codeT5.generate(input_ids, max_length=20)\n",
    "    function_source.append(tokenizer.decode(generated_ids[0], skip_special_tokens=True))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "999ad03d-1b24-48f3-8fff-9362dbbc3a18",
   "metadata": {},
   "source": [
    "## Calcul de similitude\n",
    "\n",
    "Dans la variable text est la phrase remontant l'issue, l'anomalie...\\\n",
    "Dans la suite du bloc nous comparons la similitude entre le texte et la fonction afin de trouver le fichier qu'il faudra potentiellement modifier.\\\n",
    "Nous utilisons la similarité cosinus pour faire la comparaison.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d53d4eb-5b09-422a-afe0-52c7b14d4c3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 136/136 [00:03<00:00, 43.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le fichier qui match le plus est samples/tetris.py avec une sim cos de tensor([[0.6263]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "text = 'I have a problem with the colisions of my block'\n",
    "file = ''\n",
    "max_similitude = float('-inf')\n",
    "\n",
    "for function_source in tqdm(functions_sources):\n",
    "    sentences = [text, function_source[2]]\n",
    "\n",
    "    #Compute embedding for both lists\n",
    "    embedding_1= bert.encode(sentences[0], convert_to_tensor=True)\n",
    "    embedding_2 = bert.encode(sentences[1], convert_to_tensor=True)\n",
    "\n",
    "    if max_similitude < util.pytorch_cos_sim(embedding_1, embedding_2):\n",
    "        max_similitude = util.pytorch_cos_sim(embedding_1, embedding_2)\n",
    "        file = function_source[0]\n",
    "\n",
    "print(f\"Le fichier qui match le plus est {file} avec une sim cos de {max_similitude}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
